# NLP-Model-Benchmarking-for-Various-NLP-Tasks
This repo includes various models trained for NLP various tasks such as Text classification, summarization, Q&amp;A, token classification and translation.

## Dataset

The dataset used for the experiments can be found in respective folders or it can be API calling within jupyter file. Please download the dataset separately and follow the instructions provided in the notebooks to load and preprocess the data.

## Notebooks

The repository includes Jupyter Notebook files (.ipynb) for each downstream task and model combination. The notebooks are organized as follows:

- **Text Classification**
  - BERT
  - DistillBERT
  - ALBERT
  - RoBERTa
  - BART

- **Token Classification**
  - BERT
  - DistillBERT
  - ALBERT
  - RoBERTa

- **Question Answering**
  - BERT
  - RoBERTa
  - T5
  - LongFormer
  - BigBird

- **Summarization**
  - T5
  - Pegasus
  - BigBirdPegasus

- **Translation**
  - T5

- **Extra Work**
  - BigBird
  - Longformer

Please refer to the respective notebooks for detailed instructions, code, and results.

## Document Reporting

The repository also includes a document file (Document.md) that provides a high-level summary of the project, learnings, and a comparison of the different BERT variants used. It covers topics such as the challenges faced, training times, techniques employed, and the limitations of certain models.

## Usage

To use the notebooks in this repository, follow these steps:

1. Clone the repository to your local machine.
2. Download the dataset separately from the provided link.
3. Open the desired notebook in a Jupyter Notebook environment.
4. Follow the instructions within the notebook to load the dataset, train the model, and evaluate the performance.
5. Feel free to modify the code and experiment with different hyperparameters or variations of the models.

## Contributions

Contributions to this repository are welcome! If you have any improvements, bug fixes, or additional models to add, please open a pull request. For major changes, please open an issue to discuss the proposed changes beforehand.


